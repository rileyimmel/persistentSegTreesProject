\begin{Verbatim}[commandchars=\\\{\},codes={\catcode`\$=3\catcode`\^=7\catcode`\_=8\relax}]
\PYG{k+kn}{import} \PYG{n+nn}{torch}

\PYG{k+kn}{from} \PYG{n+nn}{flow\PYGZus{}matching.path} \PYG{k+kn}{import} \PYG{n}{MixtureDiscreteProbPath}\PYG{p}{,} \PYG{n}{DiscretePathSample}
\PYG{k+kn}{from} \PYG{n+nn}{flow\PYGZus{}matching.path.scheduler} \PYG{k+kn}{import} \PYG{n}{PolynomialConvexScheduler}
\PYG{k+kn}{from} \PYG{n+nn}{flow\PYGZus{}matching.loss} \PYG{k+kn}{import} \PYG{n}{MixturePathGeneralizedKL}
\PYG{k+kn}{from} \PYG{n+nn}{flow\PYGZus{}matching.solver} \PYG{k+kn}{import} \PYG{n}{MixtureDiscreteEulerSolver}
\PYG{k+kn}{from} \PYG{n+nn}{flow\PYGZus{}matching.utils} \PYG{k+kn}{import} \PYG{n}{ModelWrapper}


\PYG{n}{model} \PYG{o}{=} \PYG{o}{...}  \PYG{c+c1}{\PYGZsh{} Define a trainable velocity model}
\PYG{n}{optimizer} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{optim}\PYG{o}{.}\PYG{n}{Adam}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{parameters}\PYG{p}{())}

\PYG{n}{scheduler} \PYG{o}{=} \PYG{n}{PolynomialConvexScheduler}\PYG{p}{(}\PYG{n}{n}\PYG{o}{=}\PYG{l+m+mf}{1.0}\PYG{p}{)}
\PYG{n}{path} \PYG{o}{=} \PYG{n}{MixtureDiscreteProbPath}\PYG{p}{(}\PYG{n}{scheduler}\PYG{o}{=}\PYG{n}{scheduler}\PYG{p}{)}
\PYG{n}{loss\PYGZus{}fn} \PYG{o}{=} \PYG{n}{MixturePathGeneralizedKL}\PYG{p}{(}\PYG{n}{path}\PYG{o}{=}\PYG{n}{path}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Generalized KL Bregman divergence}

\PYG{k}{for} \PYG{n}{x\PYGZus{}0}\PYG{p}{,} \PYG{n}{x\PYGZus{}1} \PYG{o+ow}{in} \PYG{n}{dataloader}\PYG{p}{:}  \PYG{c+c1}{\PYGZsh{} Samples from $\pi_{0,1}$ of shape [batch\PYGZus{}size, *data\PYGZus{}dim]}
    \PYG{n}{t} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{rand}\PYG{p}{(}\PYG{n}{batch\PYGZus{}size}\PYG{p}{)} \PYG{o}{*} \PYG{p}{(}\PYG{l+m+mf}{1.0} \PYG{o}{\PYGZhy{}} \PYG{l+m+mf}{1e\PYGZhy{}3}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Randomize time $t \sim U[0,1-10^{-3}]$}
    \PYG{n}{sample}\PYG{p}{:} \PYG{n}{DiscretePathSample} \PYG{o}{=} \PYG{n}{path}\PYG{o}{.}\PYG{n}{sample}\PYG{p}{(}\PYG{n}{t}\PYG{o}{=}\PYG{n}{t}\PYG{p}{,} \PYG{n}{x\PYGZus{}0}\PYG{o}{=}\PYG{n}{x\PYGZus{}0}\PYG{p}{,} \PYG{n}{x\PYGZus{}1}\PYG{o}{=}\PYG{n}{x\PYGZus{}1}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Sample the conditional path}
    \PYG{n}{model\PYGZus{}output} \PYG{o}{=} \PYG{n}{model}\PYG{p}{(}\PYG{n}{sample}\PYG{o}{.}\PYG{n}{x\PYGZus{}t}\PYG{p}{,} \PYG{n}{sample}\PYG{o}{.}\PYG{n}{t}\PYG{p}{)}

    \PYG{n}{loss} \PYG{o}{=} \PYG{n}{loss\PYGZus{}fn}\PYG{p}{(}\PYG{n}{logits}\PYG{o}{=}\PYG{n}{model\PYGZus{}output}\PYG{p}{,} \PYG{n}{x\PYGZus{}1}\PYG{o}{=}\PYG{n}{sample}\PYG{o}{.}\PYG{n}{x\PYGZus{}1}\PYG{p}{,} \PYG{n}{x\PYGZus{}t}\PYG{o}{=}\PYG{n}{sample}\PYG{o}{.}\PYG{n}{x\PYGZus{}t}\PYG{p}{,} \PYG{n}{t}\PYG{o}{=}\PYG{n}{sample}\PYG{o}{.}\PYG{n}{t}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} CDFM loss}

    \PYG{n}{optimizer}\PYG{o}{.}\PYG{n}{zero\PYGZus{}grad}\PYG{p}{()}
    \PYG{n}{loss}\PYG{o}{.}\PYG{n}{backward}\PYG{p}{()}
    \PYG{n}{optimizer}\PYG{o}{.}\PYG{n}{step}\PYG{p}{()}

\PYG{k}{class} \PYG{n+nc}{ProbabilityDenoiser}\PYG{p}{(}\PYG{n}{ModelWrapper}\PYG{p}{):}
    \PYG{k}{def} \PYG{n+nf}{forward}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{x}\PYG{p}{:} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{Tensor}\PYG{p}{,} \PYG{n}{t}\PYG{p}{:} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{Tensor}\PYG{p}{,} \PYG{o}{**}\PYG{n}{extras}\PYG{p}{)} \PYG{o}{\PYGZhy{}\PYGZgt{}} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{Tensor}\PYG{p}{:}
        \PYG{n}{logits} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{model}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{t}\PYG{p}{,} \PYG{o}{**}\PYG{n}{extras}\PYG{p}{)}
        \PYG{k}{return} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{nn}\PYG{o}{.}\PYG{n}{functional}\PYG{o}{.}\PYG{n}{softmax}\PYG{p}{(}\PYG{n}{logits}\PYG{o}{.}\PYG{n}{float}\PYG{p}{(),} \PYG{n}{dim}\PYG{o}{=\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Sample $X_1$}
\PYG{n}{probability\PYGZus{}denoiser} \PYG{o}{=} \PYG{n}{ProbabilityDenoiser}\PYG{p}{(}\PYG{n}{model}\PYG{o}{=}\PYG{n}{model}\PYG{p}{)}
\PYG{n}{x\PYGZus{}0} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{randint}\PYG{p}{(}\PYG{n}{size}\PYG{o}{=}\PYG{p}{[}\PYG{n}{batch\PYGZus{}size}\PYG{p}{,} \PYG{o}{*}\PYG{n}{data\PYGZus{}dim}\PYG{p}{])}  \PYG{c+c1}{\PYGZsh{} Specify the initial condition}
\PYG{n}{solver} \PYG{o}{=} \PYG{n}{MixtureDiscreteEulerSolver}\PYG{p}{(}
    \PYG{n}{model}\PYG{o}{=}\PYG{n}{probability\PYGZus{}denoiser}\PYG{p}{,}
    \PYG{n}{path}\PYG{o}{=}\PYG{n}{path}\PYG{p}{,}
    \PYG{n}{vocabulary\PYGZus{}size}\PYG{o}{=}\PYG{n}{vocabulary\PYGZus{}size}
\PYG{p}{)}

\PYG{n}{step\PYGZus{}size} \PYG{o}{=} \PYG{l+m+mi}{1} \PYG{o}{/} \PYG{l+m+mi}{100}
\PYG{n}{x\PYGZus{}1} \PYG{o}{=} \PYG{n}{solver}\PYG{o}{.}\PYG{n}{sample}\PYG{p}{(}\PYG{n}{x\PYGZus{}init}\PYG{o}{=}\PYG{n}{x\PYGZus{}0}\PYG{p}{,} \PYG{n}{step\PYGZus{}size}\PYG{o}{=}\PYG{n}{step\PYGZus{}size}\PYG{p}{,} \PYG{n}{time\PYGZus{}grid}\PYG{o}{=}\PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{([}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1e\PYGZhy{}3}\PYG{p}{]))}
\end{Verbatim}
